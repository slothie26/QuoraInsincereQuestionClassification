{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "num_files = 2\n",
    "embedding_size = 300\n",
    "question_size = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concatenated_embeddings(temp_df):\n",
    "#        print(\"tdf\", temp_df.shape)\n",
    "        zero_embeddings = np.zeros(embedding_size)\n",
    "        truncated_df = temp_df[:question_size]\n",
    "#        print(truncated_df.shape)\n",
    "#        print(len(truncated_df),len(truncated_df[0]))\n",
    "#        print(type([zero_embeddings]*(question_size-len(truncated_df))))\n",
    "#        print(np.array([zero_embeddings]*(question_size - len(truncated_df))).shape)\n",
    "        if(len(truncated_df)!=30):\n",
    "            truncated_df = np.concatenate((truncated_df, np.array([zero_embeddings]*(question_size- len(truncated_df)))))\n",
    "#        truncated_df.append(zero_embeddings*(question_size - len(truncated_df)))\n",
    "        return truncated_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen(n_batches,y,all_embeddings):\n",
    "#    print(\"bg\")\n",
    "    while True: \n",
    "        for i in range(n_batches):\n",
    "#            print(\"for loop\")\n",
    "            embeddings_list = all_embeddings[i*batch_size:(i+1)*batch_size] \n",
    "#           print(\"el\",embeddings_list.shape,all_embeddings.shape,embeddings_list[0].shape)\n",
    "            concat_embed_ques = np.array([get_concatenated_embeddings(ques) for ques in embeddings_list])\n",
    "            #print(i,concat_embed_ques.shape)\n",
    "            yield concat_embed_ques, np.array(y[i*batch_size:(i+1)*batch_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set 112000\n",
      "test set 60000\n",
      "val set 28000\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "all_embeddings = pickle.load(open(\"merged_embeddings_train\",\"rb\"))\n",
    "#all_embeddings_test = pickle.load(open(\"merged_embeddings_test\",\"rb\"))\t\n",
    "#print(all_embeddings.shape, all_embeddings[0].shape)\n",
    "#print(type(all_embeddings),type(all_embeddings[0]))\n",
    "all_embeddings_train, all_embeddings_test,all_y_train,all_y_test = train_test_split(all_embeddings, train_df[\"target\"][0:all_embeddings.shape[0]], test_size = 0.30, random_state = 42)\n",
    "embeddings_train,embeddings_val,y_train,y_val= train_test_split(all_embeddings_train,all_y_train,test_size=0.20)\n",
    "n_batches = math.ceil(len(y_train)/batch_size)\n",
    "print(\"train set\",len(y_train))\n",
    "print(\"test set\",len(all_y_test))\n",
    "print(\"val set\",len(y_val))\n",
    "bg = batch_gen(n_batches,y_train,embeddings_train)\n",
    "val_vects = np.array([get_concatenated_embeddings(val_emb) for val_emb in embeddings_val][:3000])\n",
    "val_y = np.array(y_val[:3000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"bidirectional_1/concat_2:0\", shape=(?, 30, 128), dtype=float32)\n",
      "Tensor(\"flatten_1/Reshape:0\", shape=(?, ?), dtype=float32)\n",
      "Tensor(\"dense_1/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, use_bias=True)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional,CuDNNGRU,BatchNormalization,Activation,Dropout,Flatten\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(CuDNNGRU(64, return_sequences=True),\n",
    "                        input_shape=(30, 300)))\n",
    "print(model.layers[0].output)\n",
    "#model.add(Dense(128, activation=\"relu\"))\n",
    "#print(model.layers[1].output)\n",
    "#model.add(Dense(64, activation=\"relu\"))\n",
    "#print(model.layers[2].output)\n",
    "#model.add(BatchNormalization(momentum=0.1, epsilon=1e-05))\n",
    "#print(model.layers[3].output)\n",
    "#model.add(Activation(\"relu\"))\n",
    "#print(model.layers[4].output)\n",
    "#model.add(Dropout(0.25))\n",
    "#print(model.layers[5].output)\n",
    "#model.add(Dense(16,bias=True))\n",
    "#print(model.layers[6].output)\n",
    "#model.add(BatchNormalization(momentum=0.1, epsilon=1e-05))\n",
    "#print(model.layers[7].output)\n",
    "#model.add(Activation(\"relu\"))\n",
    "#print(model.layers[8].output)\n",
    "#model.add(Dropout(0.1))\n",
    "#print(model.layers[9].output)\n",
    "model.add(Flatten())\n",
    "print(model.layers[1].output)\n",
    "model.add(Dense(1,bias=True))\n",
    "print(model.layers[2].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7f3ce51dbe80>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.2927 - acc: 0.8848 - val_loss: 0.2645 - val_acc: 0.8773\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.4144 - acc: 0.6820 - val_loss: 0.5352 - val_acc: 0.3877\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.8642 - acc: 0.1171 - val_loss: 0.9711 - val_acc: 0.0120\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.9802 - acc: 0.0070 - val_loss: 0.9939 - val_acc: 3.3333e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.9961 - acc: 0.0587 - val_loss: 0.9312 - val_acc: 0.0377\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.9248 - acc: 0.0401 - val_loss: 0.9939 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 1.0058 - acc: 4.6875e-05 - val_loss: 0.9939 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 1.0024 - acc: 7.0313e-05 - val_loss: 0.9939 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.9938 - acc: 0.0013 - val_loss: 0.9939 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 1.0041 - acc: 4.6875e-05 - val_loss: 0.9939 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ce0d0d240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(bg, epochs=10,\n",
    "                    steps_per_epoch=1000,\n",
    "                    validation_data=(val_vects, val_y),\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/400 [==========>...................] - ETA: 2s"
     ]
    }
   ],
   "source": [
    "#test_vects = np.array([get_concatenated_embeddings(test_emb) for test_emb in all_embeddings_test])\n",
    "#test_y = np.array(y_test[:3000])\n",
    "test_gen=batch_gen(n_batches,all_y_test,all_embeddings_test)\n",
    "scores=model.evaluate_generator(test_gen,steps=400,verbose=1)\n",
    "print(\"Accuracy\", scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
